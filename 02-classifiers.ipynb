{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# y=pd.DataFrame(labels)\n",
    "# X=pd.DataFrame(data)\n",
    "# X.to_csv('data.csv')\n",
    "# y.to_csv('labels.csv')\n",
    "\n",
    "y=pd.read_csv('labels.csv')\n",
    "X=pd.read_csv('data.csv')\n",
    "\n",
    "X=X.drop(columns='Unnamed: 0')\n",
    "y=y.drop(columns='Unnamed: 0')\n",
    "\n",
    "y=y['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_participants</th>\n",
       "      <th>total_unit_buyers</th>\n",
       "      <th>total_unit_sellers</th>\n",
       "      <th>avg_unit_buyers</th>\n",
       "      <th>avg_unit_sellers</th>\n",
       "      <th>avg_unit_buyers_hour</th>\n",
       "      <th>avg_unit_sellers_hour</th>\n",
       "      <th>avg_prices_buyers</th>\n",
       "      <th>avg_prices_sellers</th>\n",
       "      <th>avg_prices_buyers_hour</th>\n",
       "      <th>avg_prices_sellers_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>15793.000000</td>\n",
       "      <td>15793.000000</td>\n",
       "      <td>544.586207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>544.586207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.304628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.304628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>14528.000000</td>\n",
       "      <td>14528.000000</td>\n",
       "      <td>484.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>484.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.325267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.325267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>19945.000000</td>\n",
       "      <td>19945.000000</td>\n",
       "      <td>664.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>664.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.330762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.330762</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>24795.000000</td>\n",
       "      <td>24795.000000</td>\n",
       "      <td>826.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>826.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.336607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.336607</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>19872.000000</td>\n",
       "      <td>19872.000000</td>\n",
       "      <td>662.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>662.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.327053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.327053</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25915</th>\n",
       "      <td>30</td>\n",
       "      <td>17233.261194</td>\n",
       "      <td>17233.261194</td>\n",
       "      <td>718.052550</td>\n",
       "      <td>27.936253</td>\n",
       "      <td>731.717723</td>\n",
       "      <td>132.142738</td>\n",
       "      <td>15.272920</td>\n",
       "      <td>13.021347</td>\n",
       "      <td>15.426337</td>\n",
       "      <td>13.091846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25916</th>\n",
       "      <td>30</td>\n",
       "      <td>16336.487892</td>\n",
       "      <td>16336.487892</td>\n",
       "      <td>628.326457</td>\n",
       "      <td>51.837408</td>\n",
       "      <td>733.420111</td>\n",
       "      <td>41.432438</td>\n",
       "      <td>15.339325</td>\n",
       "      <td>13.048165</td>\n",
       "      <td>15.433825</td>\n",
       "      <td>13.100322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25917</th>\n",
       "      <td>30</td>\n",
       "      <td>18576.908419</td>\n",
       "      <td>18576.908419</td>\n",
       "      <td>688.033645</td>\n",
       "      <td>12.871688</td>\n",
       "      <td>693.656345</td>\n",
       "      <td>32.072690</td>\n",
       "      <td>15.373002</td>\n",
       "      <td>13.046797</td>\n",
       "      <td>15.457781</td>\n",
       "      <td>13.164231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25918</th>\n",
       "      <td>30</td>\n",
       "      <td>26115.147290</td>\n",
       "      <td>26115.147290</td>\n",
       "      <td>967.227677</td>\n",
       "      <td>38.407415</td>\n",
       "      <td>1004.855659</td>\n",
       "      <td>26.496458</td>\n",
       "      <td>14.742667</td>\n",
       "      <td>12.623373</td>\n",
       "      <td>14.863246</td>\n",
       "      <td>12.362953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25919</th>\n",
       "      <td>30</td>\n",
       "      <td>18775.305350</td>\n",
       "      <td>18775.305350</td>\n",
       "      <td>853.422970</td>\n",
       "      <td>411.837529</td>\n",
       "      <td>756.801411</td>\n",
       "      <td>335.489904</td>\n",
       "      <td>14.743938</td>\n",
       "      <td>12.436667</td>\n",
       "      <td>14.852464</td>\n",
       "      <td>12.544618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25920 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_of_participants  total_unit_buyers  total_unit_sellers  \\\n",
       "0                       29       15793.000000        15793.000000   \n",
       "1                       30       14528.000000        14528.000000   \n",
       "2                       30       19945.000000        19945.000000   \n",
       "3                       30       24795.000000        24795.000000   \n",
       "4                       30       19872.000000        19872.000000   \n",
       "...                    ...                ...                 ...   \n",
       "25915                   30       17233.261194        17233.261194   \n",
       "25916                   30       16336.487892        16336.487892   \n",
       "25917                   30       18576.908419        18576.908419   \n",
       "25918                   30       26115.147290        26115.147290   \n",
       "25919                   30       18775.305350        18775.305350   \n",
       "\n",
       "       avg_unit_buyers  avg_unit_sellers  avg_unit_buyers_hour  \\\n",
       "0           544.586207          0.000000            544.586207   \n",
       "1           484.266667          0.000000            484.266667   \n",
       "2           664.833333          0.000000            664.833333   \n",
       "3           826.500000          0.000000            826.500000   \n",
       "4           662.400000          0.000000            662.400000   \n",
       "...                ...               ...                   ...   \n",
       "25915       718.052550         27.936253            731.717723   \n",
       "25916       628.326457         51.837408            733.420111   \n",
       "25917       688.033645         12.871688            693.656345   \n",
       "25918       967.227677         38.407415           1004.855659   \n",
       "25919       853.422970        411.837529            756.801411   \n",
       "\n",
       "       avg_unit_sellers_hour  avg_prices_buyers  avg_prices_sellers  \\\n",
       "0                   0.000000          15.304628            0.000000   \n",
       "1                   0.000000          15.325267            0.000000   \n",
       "2                   0.000000          15.330762            0.000000   \n",
       "3                   0.000000          15.336607            0.000000   \n",
       "4                   0.000000          15.327053            0.000000   \n",
       "...                      ...                ...                 ...   \n",
       "25915             132.142738          15.272920           13.021347   \n",
       "25916              41.432438          15.339325           13.048165   \n",
       "25917              32.072690          15.373002           13.046797   \n",
       "25918              26.496458          14.742667           12.623373   \n",
       "25919             335.489904          14.743938           12.436667   \n",
       "\n",
       "       avg_prices_buyers_hour  avg_prices_sellers_hour  \n",
       "0                   15.304628                 0.000000  \n",
       "1                   15.325267                 0.000000  \n",
       "2                   15.330762                 0.000000  \n",
       "3                   15.336607                 0.000000  \n",
       "4                   15.327053                 0.000000  \n",
       "...                       ...                      ...  \n",
       "25915               15.426337                13.091846  \n",
       "25916               15.433825                13.100322  \n",
       "25917               15.457781                13.164231  \n",
       "25918               14.863246                12.362953  \n",
       "25919               14.852464                12.544618  \n",
       "\n",
       "[25920 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    DecisionTreeClassifier(criterion='entropy', max_depth=17, class_weight=\"balanced\"),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=17, class_weight=\"balanced\", n_jobs=-1),\n",
    "    LogisticRegression(solver='saga', max_iter=600, class_weight=\"balanced\", n_jobs=-1),\n",
    "    SVC(class_weight=\"balanced\"),\n",
    "    GaussianNB(),\n",
    "    GradientBoostingClassifier(),\n",
    "    XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=17, n_jobs=-1),\n",
    "    AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=5)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=17)\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=17, n_jobs=-1)\n",
      "LogisticRegression(class_weight='balanced', max_iter=600, n_jobs=-1,\n",
      "                   solver='saga')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erfoo/books/papers/p2p-energy-trading/mine/codes/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(class_weight='balanced')\n",
      "GaussianNB()\n",
      "GradientBoostingClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=17,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erfoo/books/papers/p2p-energy-trading/mine/codes/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:44:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=5))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erfoo/books/papers/p2p-energy-trading/mine/codes/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#train the models\n",
    "for model in classifiers:\n",
    "    print(model)\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=17)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.26      0.11       370\n",
      "           1       0.07      0.24      0.10       373\n",
      "           2       0.22      0.35      0.27      1093\n",
      "           3       0.65      0.14      0.23      3348\n",
      "\n",
      "    accuracy                           0.20      5184\n",
      "   macro avg       0.25      0.25      0.18      5184\n",
      "weighted avg       0.47      0.20      0.22      5184\n",
      "\n",
      "0.2027391975308642\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=17, n_jobs=-1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.01      0.02       370\n",
      "           1       0.14      0.01      0.02       373\n",
      "           2       0.21      0.06      0.09      1093\n",
      "           3       0.65      0.93      0.76      3348\n",
      "\n",
      "    accuracy                           0.61      5184\n",
      "   macro avg       0.27      0.25      0.22      5184\n",
      "weighted avg       0.48      0.61      0.51      5184\n",
      "\n",
      "0.6126543209876543\n",
      "\n",
      "LogisticRegression(class_weight='balanced', max_iter=600, n_jobs=-1,\n",
      "                   solver='saga')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.38      0.11       370\n",
      "           1       0.07      0.48      0.13       373\n",
      "           2       0.18      0.02      0.04      1093\n",
      "           3       0.63      0.08      0.14      3348\n",
      "\n",
      "    accuracy                           0.12      5184\n",
      "   macro avg       0.24      0.24      0.10      5184\n",
      "weighted avg       0.46      0.12      0.12      5184\n",
      "\n",
      "0.11766975308641975\n",
      "\n",
      "SVC(class_weight='balanced')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.36      0.11       370\n",
      "           1       0.07      0.62      0.13       373\n",
      "           2       0.00      0.00      0.00      1093\n",
      "           3       0.00      0.00      0.00      3348\n",
      "\n",
      "    accuracy                           0.07      5184\n",
      "   macro avg       0.03      0.24      0.06      5184\n",
      "weighted avg       0.01      0.07      0.02      5184\n",
      "\n",
      "0.07021604938271606\n",
      "\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       370\n",
      "           1       0.40      0.01      0.01       373\n",
      "           2       0.00      0.00      0.00      1093\n",
      "           3       0.65      1.00      0.78      3348\n",
      "\n",
      "    accuracy                           0.65      5184\n",
      "   macro avg       0.26      0.25      0.20      5184\n",
      "weighted avg       0.45      0.65      0.51      5184\n",
      "\n",
      "0.6458333333333334\n",
      "\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       370\n",
      "           1       0.00      0.00      0.00       373\n",
      "           2       0.07      0.00      0.00      1093\n",
      "           3       0.65      1.00      0.78      3348\n",
      "\n",
      "    accuracy                           0.64      5184\n",
      "   macro avg       0.18      0.25      0.20      5184\n",
      "weighted avg       0.43      0.64      0.51      5184\n",
      "\n",
      "0.6435185185185185\n",
      "\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=17,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=-1, num_parallel_tree=None, objective='multi:softprob', ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       370\n",
      "           1       0.21      0.01      0.02       373\n",
      "           2       0.22      0.05      0.08      1093\n",
      "           3       0.65      0.95      0.77      3348\n",
      "\n",
      "    accuracy                           0.62      5184\n",
      "   macro avg       0.27      0.25      0.22      5184\n",
      "weighted avg       0.48      0.62      0.51      5184\n",
      "\n",
      "0.6228780864197531\n",
      "\n",
      "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=5))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.01      0.02       370\n",
      "           1       0.03      0.01      0.01       373\n",
      "           2       0.23      0.04      0.07      1093\n",
      "           3       0.65      0.93      0.76      3348\n",
      "\n",
      "    accuracy                           0.61      5184\n",
      "   macro avg       0.25      0.25      0.22      5184\n",
      "weighted avg       0.47      0.61      0.51      5184\n",
      "\n",
      "0.6128472222222222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in classifiers:\n",
    "    y_pred = model.predict(X_test)\n",
    "    # y_train_pred = model.predict(X_train)\n",
    "    # evaluate the model\n",
    "    print(model)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
